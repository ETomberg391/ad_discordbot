# Channel IDs can be obtained by enabling "Developer Mode" for your discord account. Then, simply right-click on a channel and "Get Channel ID"

# Main Discord settings
discord:

  # **BOT TOKEN IS REQUIRED** (https://discordpy.readthedocs.io/en/stable/discord.html)
  TOKEN: ""
  # Feature for the bot to automatically react to messages to indicate special attributes in chat history (hidden, regenerated, continued, etc)
  history_reactions:
    enabled: true
    hidden_emoji: 'üôà'
    regen_emoji: 'üîÉ'
    continue_emoji: '‚è©'
  direct_messages:
    allow_chatting: true                  # Allows the bot to interact in direct messages (DMs). Most commands are disabled by default.
    allowed_commands: ['image', 'speak', 'prompt']  # Exclude commands by removing them from list. [] = all disabled
  embed_settings:
    color: 0x1e1f22 # Customize your embeds (0x_______) https://imagecolorpicker.com/
    show_embeds:    # Set false for any embeds you wish disabled
      system: true  # Information / System messages
      images: true  # Embeds related to image generation
      changes: true # Embeds related to character / model changes
      flows: true   # Embeds for the Flows feature
  # Feature for bot to copy current settings in a dedicated channel when changing settings via commands (ei: /imgmodel).
  post_active_settings:
    enabled: true # When enabled, you can set a "Settings Channel" for each server the bot is in via command '/set_server_settings_channel'
    post_settings_for: ['behavior', 'character', 'tags', 'imgmodel', 'llmstate'] # Limit the settings to be posted by removing them from list.
  # Feature for bot to automatically send a copy of image to starboard channel.
  starboard:
    enabled: true
    min_reactions: 2                        # number of reactions
    emoji_specific: false
    react_emojis: ['‚úÖ', 'üëè']             # for if 'emoji_specific: true'
    target_channel_id: 11111111111111111111 # bot requires message / msg management permissions


# If enabled, user settings will be managed seperately for each server (excluding the settings here in config.yaml)
per_server_settings:
  enabled: false
  # The following settings only apply if 'enabled = true'
  per_server_characters: false # **If enabled, all characters must share the same avatar.**
  character_avatar: '' # The name of an image file in your 'user_images' directory. Do not include the extension (.png/.jpg/.gif)
  # Only enable the following if: (1) You have lots of free VRAM (2) Your client settings allow multiple models to be loaded in VRAM.
  per_server_imgmodel_settings: false # In addition to separate settings, this uses the payload to drive model handling (instead of /models API).


# Dynamic Prompting feature. Uses similar syntax and usage as the SD WebUI extension 'sd-dynamic-prompts'.
# More details here: https://github.com/altoiddealer/ad_discordbot/wiki/dynamic-prompting
dynamic_prompting_enabled: true


# Main textgen-webui settings
# Note: Many native textgen-webui settings are honored: 'CMD_FLAGS.txt' (extensions) / 'settings.yaml' / 'models/config-user.yaml' (LLM model settings)
textgenwebui:
  enabled: true                         # Controls whether TGWUI is part of the bot (does not register relavent commands for discord, etc)
  TGWUI_URL: "http://127.0.0.1:7861"    # Currently a placeholder value for if this bot switches to using the TGWUI API
  # History handling settings
  chat_history:
    limit_history: true                 # Recommended to keep as true. This will limit the stored history to roughly the current 'truncation_length' (more than enough retained). You may have performance issues if set to false.
    autosave_history: false             # Set this value to true to continuously save history. Use '/save_conversation' to manually save your conversation.
    export_for_tgwui: true              # Defines if your history save can be later imported into standalone text-generation-webui.
    autoload_history: false             # Set to true if you want the character to load with the most recently saved chat history.
    change_char_history_method: new     # 'new' - start new history; 'keep' - retain history for next character (only applicable if 'autoload_history: true')
    greeting_or_history: history        # 'history' - Sends copy of most recent message exchange whenever history is loaded; 'greeting' - Only send character's greeting
    per_channel_history: true           # If true, each channel will have its own chat history. Log files will not be compatible with text-generation-webui unless processed by .bat in '/utils/'

  # Supported TTS Clients: 'alltalk_tts', 'coqui_tts', 'silero_tts', 'edge_tts' and 'elevenlabs_tts' have been tested. Other tts extensions may work.
  # REQUIRES: 'pip install pynacl' in textgen-webui venv for bot to join a voice channel
  # Use command '/set_server_voice_channel' in each server that you want to connect to voice channel for playing TTS
  tts_settings:
    extension: ''                       # '' = Disabled. Ex: 'alltalk_tts' (Loads automatically. Don't include in '--extensions' launch flag)
    api_key: ''                         # May be required for some tts extensions (ex: elevenlabs_tts)
    play_mode: 2                        # 0 = use voice channel / 1 = upload file to chat channel / 2 = both (use voice & upload file)
    mp3_bit_rate: 128                   # If play_mode = 1 or 2, and the output (.wav) exceeds 8MB (discord limit), it will convert to .mp3 before uploading.
    save_mode: 1                        # 0 = save outputs / 1 = try deleting outputs. Note: Can't delete outputs uploaded to channel. (../extensions/coqui_tts/outputs)
    tts_greeting: true                  # Whether to generate TTS for greeting when using '/character' or '/reset_conversation'
    tts_streaming: true                 # Setting only valid if character behavior has `chance_to_stream_reply`. Set to "false" if you want text streaming and TTS, but not TTS streaming.


# Main SD WebUI settings
sd:
  enabled: true                         # Controls whether SD WebUI is part of the bot (does not register relavent commands for discord, etc)
  SD_URL: "http://127.0.0.1:7860"       # Default URL for A1111 API. Adjust if you have issues connecting.
  extensions:                           # Only set extensions as True if they are installed AND active in your A1111.
    controlnet_enabled: false           # Requires: sd-webui-controlnet (https://github.com/Mikubill/sd-webui-controlnet) AND configuring 'dict_cmdoptions.yaml'
    forgecouple_enabled: false          # Requires: sd-forge-couple (https://github.com/Haoming02/sd-forge-couple) **Only works for Forge, not A1111**
    layerdiffuse_enabled: false         # Requires: sd-forge-layerdiffuse (https://github.com/layerdiffusion/sd-forge-layerdiffuse) **Only works for Forge, not A1111**
    reactor_enabled: false              # Requires: sd-webui-reactor (https://github.com/Gourieff/sd-webui-reactor)
    # 'sd-loractl' extension enhances LORA processing by allowing adjustable weights during image generation.
    # This bot can automatically calculate and apply weight scaling as defined below.
    lrctl:                              # Requires: sd-webui-loractl (https://github.com/cheald/sd-webui-loractl)
      enabled: false                    # **Only works for A1111 and ReForge, not Forge**
      min_loras: 2                      # Minimum number of loras in the prompt to trigger the following weight scaling definitions.
      # format is (% of existing lora weight)@(step percent),(more step definitions). These are not static weights- these are multiplied by the existing LORA weight. '1.0@0' = begin generation with existing LORA weight.
      # You can define as many steps as you want. ex1: '0.5@0' would just cut the LORA weight in half. ex2: '0.0@0,1.0@0.5,0.0@1.0' would look like a pyramid on the graph.
      lora_1_scaling: '1.0@0,0.5@0.5'
      lora_2_scaling: '0.5@0,1.0@0.5'
      # More scaling definitions can be added ex: 'lora_3_scaling' etc
      # Applies to LORAs when there are more in the prompt than defined above. ei: If 4 loras are found in prompt, but only defined up to lora_2_scaling, then the last 2 LORAs would be scaled by this definition.
      additional_loras_scaling: '0.4@0.0,0.8@0.5'
